---
title: "Set up human evaluators"
description: "A guide on how to set up human evaluators."
---

Although LLMs are powerful, they are not perfect. They can make mistakes, and sometimes the mistakes are hard to detect. Human review is a way to ensure the quality of the LLM output and the accuracy of the AI evaluators.

## Set up human evaluators
<Steps>
<Step title="Create a new evaluator">
You can set up an evaluator in [Evaluators](https://platform.respan.ai/platform/evaluators). Click the **+ New evaluator** button, and select **Human**.

<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/evaluations/create-evaluator.png"/>
</Frame>

</Step>

<Step title="Configure the evaluator">
Name the evaluator, and add a description. Then you can choose the type of the evaluation metric. We currently support **Boolean** and **Numerical** metrics.

<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/evaluations/human-evals/config.png"/>
</Frame>
</Step>

<Step title="Annotate LLM logs in Logs">
You can annotate LLM logs in the side panel **Scores** of[Logs](https://platform.respan.ai/platform/logs).

<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/evaluations/human-evals/annotation.png"/>
</Frame>
</Step>

</Steps>






